# -*- coding: utf-8 -*-
"""CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vvEYjSLHizkiNOoFzsaz9ZG5LH0-rDUx
"""

import tensorflow as tf
from keras import Input
from keras.models import Sequential
from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

"""# ***Part 0***"""

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()

"""# ***Part 1***"""

model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(10, activation='softmax'))
model.summary()

"""# ***Part 2***"""

model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

rep = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

plt.plot(rep.history['accuracy'], label='accuracy')
plt.plot(rep.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')

plt.plot(rep.history['loss'], label='loss')
plt.plot(rep.history['val_loss'], label = 'val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0, 2])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(test_acc)

"""# ***Part 3***"""

import numpy as np

def global_contrast_normalization(image):
    XX = image

    # replacement for the loop
    X_average = np.mean(XX)
    XX = XX - X_average
    
    ss   = 1.0
    lmda = 10.
    contrast = np.sqrt(lmda + np.mean(XX**2)).astype(np.float64)
    
    if contrast > 1e-8:
        XX = ss * XX / contrast
    else:
        XX = ss * XX 

    return XX

x_train = np.asarray(x_train)
x_test = np.asarray(x_test)

gcn_train = np.asarray([global_contrast_normalization(x) for x in x_train])
gcn_test = np.asarray([global_contrast_normalization(x) for x in x_test])

gcn_train = (gcn_train - gcn_train.min(axis=(1,2))[:,None,None,:] )/(gcn_train.max(axis=(1,2))-gcn_train.min(axis=(1,2)))[:,None,None,:]
gcn_test = (gcn_test - gcn_test.min(axis=(1,2))[:,None,None,:] )/(gcn_test.max(axis=(1,2))-gcn_test.min(axis=(1,2)))[:,None,None,:]

model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

rep = model.fit(gcn_train, y_train, epochs=10, validation_data=(gcn_test, y_test))

plt.plot(rep.history['accuracy'], label='accuracy')
plt.plot(rep.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')

plt.plot(rep.history['loss'], label='loss')
plt.plot(rep.history['val_loss'], label = 'val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0, 2])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(gcn_test, y_test, verbose=2)
print(test_acc)

"""# ***Part 4***

***a)***
"""

model_a = Sequential()
model_a.add(Conv2D(512, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))
model_a.add(MaxPooling2D((4, 4)))
model_a.add(Flatten())
model_a.add(Dense(10, activation='softmax'))
model_a.summary()

model_a.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

rep_a = model_a.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

plt.plot(rep_a.history['accuracy'], label='accuracy')
plt.plot(rep_a.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')

test_loss_a, test_acc_a = model_a.evaluate(x_test, y_test, verbose=2)
print(test_acc_a)

"""***b)***"""

model_b = Sequential()
model_b.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))
model_b.add(MaxPooling2D((2, 2)))
model_b.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
model_b.add(MaxPooling2D((2, 2)))
model_b.add(Conv2D(128, (4, 4), padding='same', activation='relu'))
model_b.add(MaxPooling2D((2, 2)))
model_b.add(Conv2D(128, (3, 3), padding='same', activation='relu'))
model_b.add(MaxPooling2D((2, 2)))
model_b.add(Flatten())
model_b.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
model_b.add(Dense(10, activation='softmax'))
model_b.summary()

model_b.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

rep_b = model_b.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

plt.plot(rep_b.history['accuracy'], label='accuracy')
plt.plot(rep_b.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')

test_loss_b, test_acc_b = model_b.evaluate(x_test, y_test, verbose=2)
print(test_acc_b)